{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fbdb5c",
   "metadata": {},
   "source": [
    "In this notebook, we will build a 3D map of a scene from a small set of images and then localize an image downloaded from the Internet. This demo was contributed by [Philipp Lindenberger](https://github.com/Phil26AT/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "import os, sys\n",
    "BASEPATH = os.getcwd().split('code')[-2]\n",
    "sys.path.append(os.path.join(BASEPATH, 'code'))\n",
    "from utils import pairs_from_sequence, pairs_from_360\n",
    "\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "import copy\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive\n",
    ")\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "import pycolmap\n",
    "\n",
    "from utils.multiview_utils import Camera, Calibration\n",
    "from utils.metadata_utils import get_cam_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ac394",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Here we define some output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arv_copy = sys.argv\n",
    "sys.argv = ['pop']\n",
    "sys.argv.append('-cfg')\n",
    "config_path = os.path.abspath('../../code/configs/project_config.yaml')\n",
    "sys.argv.append(config_path)\n",
    "sys.argv.append('-dr')\n",
    "root_path = os.path.abspath('../../data/')\n",
    "sys.argv.append(root_path)\n",
    "sys.argv.append('-l')\n",
    "sys.argv.append('info')\n",
    "\n",
    "RESTART = False # set true if wanting to run everything from scratch\n",
    "\n",
    "\n",
    "images = Path(\"../../data/0-calibration/images\")\n",
    "outputs = Path(\"../../data/0-calibration/outputs/\")\n",
    "if RESTART:\n",
    "    if os.path.exists(output_directory):\n",
    "        # Remove all contents and the directory itself\n",
    "        shutil.rmtree(output_directory)\n",
    "        print(f\"Removed directory and its contents: {output_directory}\")\n",
    "    else:\n",
    "        print(f\"Directory does not exist: {output_directory}\")\n",
    "# outputs.mkdir(exist_ok=True)\n",
    "sfm_pairs = outputs / \"pairs-sfm.txt\"\n",
    "loc_pairs = outputs / \"pairs-loc.txt\"\n",
    "sfm_dir = outputs / \"sfm\"\n",
    "features = outputs / \"features.h5\"\n",
    "matches = outputs / \"matches.h5\"\n",
    "\n",
    "feature_conf = extract_features.confs[\"disk\"]\n",
    "matcher_conf = match_features.confs[\"disk+lightglue\"]\n",
    "# feature_conf = extract_features.confs[\"superpoint_aachen\"]\n",
    "# matcher_conf = match_features.confs[\"superpoint+lightglue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7b21e",
   "metadata": {},
   "source": [
    "# 3D mapping\n",
    "First we list the images used for mapping. These are all day-time shots of Sacre Coeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# references = [p.relative_to(images).as_posix() for p in (images).iterdir() if '360' in p.name]\n",
    "references = [p.relative_to(images).as_posix() for p in images.rglob('*.jpg') if '360' in p.parent.name]\n",
    "print(len(references), \"mapping images\")\n",
    "# plot_images([read_image(images / r) for r in references], dpi=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23739ad",
   "metadata": {},
   "source": [
    "Then we extract features and match them across image pairs. Since we deal with few images, we simply match all pairs exhaustively. For larger scenes, we would use image retrieval, as demonstrated in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESTART:\n",
    "\n",
    "    extract_features.main(\n",
    "        feature_conf, images, image_list=references, feature_path=features\n",
    "    )\n",
    "\n",
    "    pairs_from_360.main(sfm_pairs, image_dir=images, window_size=4)\n",
    "\n",
    "    match_features.main(matcher_conf, sfm_pairs, features=features, matches=matches);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9adf4",
   "metadata": {},
   "source": [
    "The we run incremental Structure-From-Motion and display the reconstructed 3D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52fe785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opts = dict(camera_model = \"SIMPLE_RADIAL\", camera_params =','.join(map(str, (1, 256, 256, 0))))\n",
    "if RESTART:\n",
    "    model = reconstruction.main(\n",
    "        sfm_dir, images, sfm_pairs, features, matches, image_list=references, camera_mode=pycolmap.CameraMode.PER_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85021248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = outputs / 'full_reconstruction/'\n",
    "\n",
    "model_dir.mkdir(exist_ok = True, parents = True)\n",
    "if RESTART:\n",
    "    model.write(model_dir)\n",
    "\n",
    "# load reconstruction\n",
    "\n",
    "model = pycolmap.Reconstruction(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8275b0",
   "metadata": {},
   "source": [
    "# Localise Static Cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [p.relative_to(images).as_posix() for p in images.rglob('*.jpg') if '360' not in p.parent.name]\n",
    "\n",
    "extract_features.main(\n",
    "    feature_conf, images, image_list=query, feature_path=features, overwrite=True\n",
    ")\n",
    "pairs_from_exhaustive.main(loc_pairs, image_list=query, ref_list=references)\n",
    "\n",
    "\n",
    "match_features.main(\n",
    "    matcher_conf, loc_pairs, features=features, matches=matches, overwrite=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39642b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycolmap\n",
    "from hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "from utils.colmap_utils import add_camera_and_image, camera_calibs_from_colmap\n",
    "\n",
    "\n",
    "# camera = pycolmap.infer_camera_from_image(images / query)\n",
    "ref_ids = [model.find_image_with_name(r).image_id for r in references if model.find_image_with_name(r) is not None]\n",
    "conf = {\n",
    "    \"estimation\": {\"ransac\": {\"max_error\": 12}},\n",
    "    \"refinement\": {\"refine_focal_length\": False, \"refine_extra_params\": False},\n",
    "}\n",
    "localizer = QueryLocalizer(model, conf)\n",
    "rets = []\n",
    "logs = []\n",
    "for query_ in query:\n",
    "    camera = pycolmap.infer_camera_from_image(images / query_)\n",
    "    camera.params = [640, 640, 340, 0]\n",
    "    ret, log = pose_from_cluster(localizer, query_, camera, ref_ids, features, matches)\n",
    "    ret['image'] = query_\n",
    "    # add results to reconstruction\n",
    "    try:\n",
    "        add_camera_and_image(model, ret['camera'], ret[\"cam_from_world\"], ret[\"image\"])\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "    rets.append(ret)\n",
    "    logs.append(log)\n",
    "    # visualise found matches for verification\n",
    "    print(f'found {ret[\"num_inliers\"]}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "    visualization.visualize_loc_from_log(images, query_, log, model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa15829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define necessary functions for ray-plane intersection\n",
    "def ray_plane_intersection(ray_origin, ray_direction, plane_normal, plane_point):\n",
    "    d = np.dot(plane_normal, plane_point)\n",
    "    t = (d - np.dot(plane_normal, ray_origin)) / np.dot(plane_normal, ray_direction)\n",
    "    return ray_origin + t * ray_direction\n",
    "\n",
    "def image_to_world_coordinates(cam, roi_points, z_plane=0):\n",
    "    intrinsic = cam.calibration.intrinsic  # Expecting a 3x3 numpy array\n",
    "    rotation = cam.rotation_matrix()  # Rotation matrix of the camera\n",
    "    translation = cam.translation_vector()  # Translation vector of the camera\n",
    "    \n",
    "    plane_normal = np.array([0, 0, 1])\n",
    "    plane_point = np.array([0, 0, z_plane])\n",
    "\n",
    "    world_points = []\n",
    "    for point in roi_points:\n",
    "        x, y = point\n",
    "        # Convert image coordinates to normalized camera coordinates\n",
    "        normalized_coords = np.linalg.inv(intrinsic) @ np.array([x, y, 1])\n",
    "        # Convert normalized camera coordinates to world coordinates\n",
    "        ray_direction = rotation @ normalized_coords\n",
    "        ray_origin = translation\n",
    "        # Find the intersection of the ray with the plane z=0\n",
    "        world_point = ray_plane_intersection(ray_origin, ray_direction, plane_normal, plane_point)\n",
    "        world_points.append(world_point)\n",
    "    \n",
    "    return np.array(world_points)\n",
    "\n",
    "\n",
    "def plot_reconstruction(model):\n",
    "\n",
    "    \"\"\"plots a pycolmap reconstruction and adds regions of interest for the cameras\n",
    "    \"\"\"\n",
    "    config = get_config_dict()\n",
    "    fig = viz_3d.init_figure()\n",
    "    \n",
    "    viz_3d.plot_reconstruction(\n",
    "    fig, temp_model, color=\"rgba(255,0,0,0.5)\", name=\"mapping\", points_rgb=True\n",
    "    )\n",
    "\n",
    "    mvvids = MultiviewVids(newest=False, config=config)\n",
    "    mvvids.cams = camera_calibs_from_colmap(images, temp_model, save=False)\n",
    "\n",
    "    bbx = model.compute_bounding_box(0.01, 0.99)\n",
    "\n",
    "    # Add a static plane at z=0\n",
    "    plane = go.Mesh3d(\n",
    "        x=[bbx[0][0], bbx[1][0], bbx[1][0], bbx[0][0]],\n",
    "        y=[bbx[0][1], bbx[0][1], bbx[1][1], bbx[1][1]],\n",
    "        z=[0, 0, 0, 0],\n",
    "        color='lightblue',\n",
    "        opacity=0.5,\n",
    "        name='Plane at z=0',\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "    fig.add_trace(plane)\n",
    "\n",
    "    # Process the cameras and plot the ROI intersection with the plane z=0\n",
    "    for cam in mvvids.cams:\n",
    "        roi_image_coords = cam.calibration.ROI\n",
    "        roi_camera_coords = cam.from_image(roi_image_coords)\n",
    "        roi_world_coords = cam.convert_to_world_frame(roi_camera_coords)\n",
    "\n",
    "        # Get the camera center in world coordinates\n",
    "        camera_center = cam.get_position()\n",
    "\n",
    "        plane_normal = np.array([0, 0, 1])\n",
    "        plane_point = np.array([0, 0, 0])\n",
    "\n",
    "        for point in roi_world_coords:\n",
    "            ray_direction = point - camera_center\n",
    "            intersection_point = ray_plane_intersection(camera_center, ray_direction, plane_normal, plane_point)\n",
    "            \n",
    "            # Plot the extended ray\n",
    "            line = go.Scatter3d(\n",
    "                x=[camera_center[0], intersection_point[0]],\n",
    "                y=[camera_center[1], intersection_point[1]],\n",
    "                z=[camera_center[2], intersection_point[2]],\n",
    "                mode='lines',\n",
    "                line=dict(color='blue', width=2),\n",
    "                name=f'Ray through ROI point {cam.name}'\n",
    "            )\n",
    "            fig.add_trace(line)\n",
    "\n",
    "    \n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def plot_ground_plane_proj(model, exclude:list = []):\n",
    "    \"\"\"\n",
    "    Plots the groundplane projection for the set of static cameras in the reconstruction\n",
    "    \"\"\"\n",
    "    # Initialize configuration and multiview video handler\n",
    "    config = get_config_dict()\n",
    "    mvvids = MultiviewVids(newest=False, config=config)\n",
    "    cameras = camera_calibs_from_colmap(images, temp_model, save=False)\n",
    "    mvvids.cams = [camera for camera in cameras if camera.name not in exclude]\n",
    "\n",
    "    # Extract frames\n",
    "    max_frame = np.min([10, mvvids.get_max_frame_id() - 1])\n",
    "    step = 2\n",
    "    frame_ids = list(np.arange(0, max_frame, step))\n",
    "    base_frames = mvvids.extract_mv(frame_ids, undistort=True)\n",
    "\n",
    "    # Setup plotly figure for 2D image projection\n",
    "    fig_img = go.Figure()\n",
    "\n",
    "    alphas = [1.0, 0.7, 0.5, 0.3]\n",
    "    rect, _ = mvvids.get_bounding_box()\n",
    "    output_img_size = (1920, 1080)\n",
    "    input_img_size = (1080, 1920)\n",
    "\n",
    "    for cam in mvvids.cams:\n",
    "        img = copy.deepcopy(base_frames[cam.name][0])\n",
    "        img = cv2.resize(img, (input_img_size[1], input_img_size[0]))\n",
    "        H = cam.get_ground_plane_homography(input_img_size=input_img_size, output_img_size=output_img_size, bounding_box=rect, padding_percent=0)\n",
    "        new_img = project_to_ground_plane_cv2(img, H, output_img_size)\n",
    "\n",
    "        fig_img.add_trace(go.Image(z=new_img, opacity=alphas[int(cam.calibration.view_id) - 1]))\n",
    "\n",
    "\n",
    "    return fig_img\n",
    "\n",
    "def plot_histogram(model):\n",
    "    \"\"\"\n",
    "    Plots the distribution of z-coordinates for a given pycolmap reconstruction\n",
    "    \"\"\"\n",
    "    points = np.array([point.xyz for point in model.points3D.values()])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=points[:, 2], name='Z-Value Distribution'))\n",
    "\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.multiview_utils import MultiviewVids\n",
    "from utils.metadata_utils import get_config_dict\n",
    "from hloc.utils.viz_3d import plot_camera\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import copy\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "from IPython.display import display\n",
    "from utils.coordinate_utils import project_to_ground_plane_cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "\n",
    "\n",
    "temp_model = copy.deepcopy(model)\n",
    "# Transform the model\n",
    "temp_model.transform(pycolmap.Sim3d(1, pycolmap.Rotation3d([-0.7071068, 0, 0, 0.7071068]), [0, 0, 0]))\n",
    "temp_model.transform(pycolmap.Sim3d(1, pycolmap.Rotation3d([0, 0, 0, 1]), [0, 0, -temp_model.compute_bounding_box(0.01, 0.99)[0][2]]))\n",
    "\n",
    "\n",
    "# Create the initial subplot layout\n",
    "fig_subplots = make_subplots(\n",
    "    rows=3, cols=1, \n",
    "    subplot_titles=(\"Reconstruction\", \"Ground Plane\", \"Z-Histogram\"),\n",
    "    specs=[[{'type': 'scene'}], [{'type': 'xy'}], [{'type': 'xy'}]]\n",
    ")\n",
    "\n",
    "\n",
    "def rerender_plots(new_z):\n",
    "    new_recon = copy.deepcopy(temp_model)\n",
    "    new_recon.transform(pycolmap.Sim3d(1, pycolmap.Rotation3d([0, 0, 0, 1]), [0, 0, new_z]))\n",
    "    fig_reconstruction = plot_reconstruction(new_recon)\n",
    "\n",
    "    fig_subplots.data = []\n",
    "\n",
    "    # Add extracted 3D traces to the first subplot (row=1, col=1)\n",
    "    for trace in fig_reconstruction.data:\n",
    "        fig_subplots.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    fig_img = plot_ground_plane_proj(new_recon, exclude=['cam1'])\n",
    "    for trace in fig_img.data:\n",
    "        fig_subplots.add_trace(trace, row=2, col=1)\n",
    "\n",
    "    fig_hist = plot_histogram(new_recon)\n",
    "    for trace in fig_hist.data:\n",
    "        fig_subplots.add_trace(trace, row=3, col=1)\n",
    "\n",
    "rerender_plots(0)\n",
    "# Display the figure\n",
    "recon_widget = go.FigureWidget(fig_subplots)\n",
    "display(recon_widget)\n",
    "\n",
    "# Define a button to trigger the update\n",
    "button = widgets.Button(description=\"Rerender\")\n",
    "\n",
    "# Define the button click event\n",
    "def on_button_click(b):\n",
    "    rerender_plots(z_global)\n",
    "\n",
    "# Bind the button click event\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "\n",
    "# Define the initial value for z\n",
    "z_global = 0\n",
    "\n",
    "# Create a slider widget for z\n",
    "z_slider = widgets.FloatSlider(\n",
    "    value=z_global,\n",
    "    min=-10,\n",
    "    max=10,\n",
    "    step=0.1,\n",
    "    description='Z Value:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Define a function to update the plane position based on the slider value\n",
    "def update_z(change):\n",
    "    z_global = change['new']\n",
    "    with recon_widget.batch_update():\n",
    "                for trace in recon_widget.data:\n",
    "                    if trace.name == 'Plane at z=0':\n",
    "                        trace.z += z_global\n",
    "\n",
    "# Attach the update function to the slider\n",
    "z_slider.observe(update_z, names='value')\n",
    "display(z_slider)\n",
    "display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74147d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For Downsampling\n",
    "# from hloc.utils.viz_3d import plot_points, plot_cameras\n",
    "# import random\n",
    "# def plot_reconstruction_tight(\n",
    "#     fig: go.Figure,\n",
    "#     rec: pycolmap.Reconstruction,\n",
    "#     max_reproj_error: float = 6.0,\n",
    "#     color: str = \"rgb(0, 0, 255)\",\n",
    "#     name = None,\n",
    "#     min_track_length: int = 2,\n",
    "#     points: bool = True,\n",
    "#     cameras: bool = True,\n",
    "#     points_rgb: bool = True,\n",
    "#     cs: float = 1.0,\n",
    "#     ratio = .1\n",
    "# ):\n",
    "#     # Filter outliers\n",
    "#     bbs = rec.compute_bounding_box(0.001, 0.999)\n",
    "#     # Filter points, use original reproj error here\n",
    "#     p3Ds = [\n",
    "#         p3D\n",
    "#         for _, p3D in rec.points3D.items()\n",
    "#         if (\n",
    "#             (p3D.xyz >= bbs[0]).all()\n",
    "#             and (p3D.xyz <= bbs[1]).all()\n",
    "#             and p3D.error <= max_reproj_error\n",
    "#             and p3D.track.length() >= min_track_length\n",
    "#         )\n",
    "#     ]\n",
    "#     print(len(p3Ds))\n",
    "#     p3Ds = random.sample(p3Ds, int(ratio * len(p3Ds)))\n",
    "#     xyzs = [p3D.xyz for p3D in p3Ds]\n",
    "#     if points_rgb:\n",
    "#         pcolor = [p3D.color for p3D in p3Ds]\n",
    "#     else:\n",
    "#         pcolor = color\n",
    "#     if points:\n",
    "#         plot_points(fig, np.array(xyzs), color=pcolor, ps=1, name=name)\n",
    "#     if cameras:\n",
    "#         plot_cameras(fig, rec, color=color, legendgroup=name, size=cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For Rotation of groundplane\n",
    "# # Function to update the plot based on Euler angles and translation\n",
    "# def update_plot(roll, pitch, yaw, trans_x, trans_y, trans_z):\n",
    "#     # Convert Euler angles to quaternion\n",
    "#     r = R.from_euler('xyz', [roll, pitch, yaw], degrees=True)\n",
    "#     quat = r.as_quat()  # Returns in the order [x, y, z, w]\n",
    "    \n",
    "#     # Create the transformation object\n",
    "#     rig3d = pycolmap.Rigid3d()\n",
    "#     rig3d.rotation = pycolmap.Rotation3d(quat)\n",
    "#     rig3d.translation = [trans_x, trans_y, trans_z]\n",
    "    \n",
    "#     # Get the transformation matrix (4x3)\n",
    "#     transform_matrix = rig3d.matrix()\n",
    "    \n",
    "#     # Extract rotation and translation\n",
    "#     rotation_matrix = transform_matrix[:, :3]\n",
    "#     translation_vector = transform_matrix[:, 3]\n",
    "    \n",
    "#     # Define the axes in the original frame\n",
    "#     original_axes = {\n",
    "#         'x': np.array([[0, 0, 0], [1, 0, 0]]),\n",
    "#         'y': np.array([[0, 0, 0], [0, 1, 0]]),\n",
    "#         'z': np.array([[0, 0, 0], [0, 0, 1]])\n",
    "#     }\n",
    "    \n",
    "#     # Apply the transformation to the axes\n",
    "#     transformed_axes = {\n",
    "#         axis: np.dot(points, rotation_matrix.T) + translation_vector\n",
    "#         for axis, points in original_axes.items()\n",
    "#     }\n",
    "    \n",
    "#     # Update the traces in the figure\n",
    "#     with fig.batch_update():\n",
    "#         fig.data[0].x, fig.data[0].y, fig.data[0].z = transformed_axes['x'][:, 0], transformed_axes['x'][:, 1], transformed_axes['x'][:, 2]\n",
    "#         fig.data[1].x, fig.data[1].y, fig.data[1].z = transformed_axes['y'][:, 0], transformed_axes['y'][:, 1], transformed_axes['y'][:, 2]\n",
    "#         fig.data[2].x, fig.data[2].y, fig.data[2].z = transformed_axes['z'][:, 0], transformed_axes['z'][:, 1], transformed_axes['z'][:, 2]\n",
    "#     fig.show()\n",
    "\n",
    "# # Create sliders for the Euler angles and translation components\n",
    "# roll_slider = widgets.FloatSlider(value=0, min=-180, max=180, step=1, description='Roll')\n",
    "# pitch_slider = widgets.FloatSlider(value=0, min=-180, max=180, step=1, description='Pitch')\n",
    "# yaw_slider = widgets.FloatSlider(value=0, min=-180, max=180, step=1, description='Yaw')\n",
    "# trans_x_slider = widgets.FloatSlider(value=0, min=-5, max=5, step=0.1, description='Trans X')\n",
    "# trans_y_slider = widgets.FloatSlider(value=0, min=-5, max=5, step=0.1, description='Trans Y')\n",
    "# trans_z_slider = widgets.FloatSlider(value=0, min=-5, max=5, step=0.1, description='Trans Z')\n",
    "\n",
    "# # Interactive display\n",
    "# def update(*args):\n",
    "#     update_plot(roll_slider.value, pitch_slider.value, yaw_slider.value, \n",
    "#                 trans_x_slider.value, trans_y_slider.value, trans_z_slider.value)\n",
    "\n",
    "# roll_slider.observe(update, names='value')\n",
    "# pitch_slider.observe(update, names='value')\n",
    "# yaw_slider.observe(update, names='value')\n",
    "# trans_x_slider.observe(update, names='value')\n",
    "# trans_y_slider.observe(update, names='value')\n",
    "# trans_z_slider.observe(update, names='value')\n",
    "\n",
    "# # Display widgets\n",
    "# widgets.VBox([roll_slider, pitch_slider, yaw_slider, trans_x_slider, trans_y_slider, trans_z_slider])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

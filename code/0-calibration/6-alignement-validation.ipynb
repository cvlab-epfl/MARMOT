{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4e1fd1-8430-40d5-935d-08a6b4580a2b",
   "metadata": {},
   "source": [
    "## Visualize groundplane alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8409fcd-85c5-4acb-b373-075847a00d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tqdm, tqdm.notebook\n",
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "BASEPATH = os.getcwd().split('code')[-2]\n",
    "CODEPATH = os.path.join(BASEPATH, 'code')\n",
    "DATAPATH = os.path.join(BASEPATH, 'data')\n",
    "\n",
    "sys.path.append(CODEPATH)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from configs.arguments import get_config_dict\n",
    "from utils.coordinate_utils import project_to_ground_plane_cv2, triangulate_point, project_points\n",
    "from utils.multiview_utils import Camera, Calibration\n",
    "from utils.metadata_utils import get_cam_names\n",
    "from utils.multiview_utils import MultiviewVids\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "if \"pomelo_cfg\" in os.environ:\n",
    "    sys.argv.append('-cfg')\n",
    "    config_path = os.path.abspath(os.environ[\"pomelo_cfg\"])\n",
    "    sys.argv.append(config_path)\n",
    "\n",
    "try:\n",
    "    config = get_config_dict()\n",
    "except:\n",
    "    log.warning(\"No config file found. Using default values.\")\n",
    "    config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b770040-8f53-43a6-b6fc-4e138ec83b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvvids = MultiviewVids(newest=False)\n",
    "\n",
    "max_frame = np.min([10, mvvids.get_max_frame_id() - 1])\n",
    "step = 2\n",
    "base_frames = {}\n",
    "\n",
    "frame_ids = list(np.arange(0, max_frame, step))\n",
    "\n",
    "base_frames = mvvids.extract_mv(frame_ids, undistort = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fad96-8f22-4316-89a7-ee5c8117f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize groundplane\n",
    "\n",
    "for cam in mvvids.cams:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img = base_frames[cam.name][0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4558c-509f-4a8f-9d09-22c12daa303b",
   "metadata": {},
   "source": [
    "Adjust output_img_size especially aspect ratio such that the area of interest take the most space.\n",
    "Once satisfied in the results save the value in train_config.yaml hm size.\n",
    "The range of value should be in the 100-400 range depending on gpu memory size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbe46b-a4e4-481b-8f68-f032744742bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect, _ = mvvids.get_bounding_box()\n",
    "\n",
    "output_img_size = (1000, 1500)\n",
    "padding_percent = 0\n",
    "\n",
    "ground_imgs = []\n",
    "\n",
    "for cam in mvvids.cams:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img = base_frames[cam.name][0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    input_img_size = base_frames[cam.name][0].shape[:2]\n",
    "\n",
    "    H = cam.get_ground_plane_homography(input_img_size=input_img_size, output_img_size = output_img_size, \n",
    "                                        bounding_box = rect, padding_percent = padding_percent)\n",
    "\n",
    "    new_img = project_to_ground_plane_cv2(img, H, output_img_size)\n",
    "    ground_imgs.append(new_img)\n",
    "    plt.imshow(new_img)\n",
    "    plt.show()\n",
    "\n",
    "#Overal images to see alignement\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, img in enumerate(ground_imgs):\n",
    "    plt.imshow(img, alpha=1-i/len(ground_imgs))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da7fa7-a759-4bd8-a3d1-1ca9d2ca3f9c",
   "metadata": {},
   "source": [
    "## Check groundplane alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c654d9-2ca0-4c1b-8c32-ddb16f53f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c674bb1-fade-4071-a103-77140e3c079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_3ds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8f2f2-b755-4636-b2ef-06b94775fff3",
   "metadata": {},
   "source": [
    "Select a matching ground point between at least two views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d093a8a-4f6b-44d1-88d8-56db2963829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "ann_points = {cam.name: [] for cam in mvvids.cams}\n",
    "\n",
    "# create dropdown widget with camera names as options\n",
    "cam_dropdown = widgets.Dropdown(\n",
    "    options=[cam.name for cam in mvvids.cams],\n",
    "    value=mvvids.cams[0].name,\n",
    "    description='Camera:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def onclick(event, cam):\n",
    "    ax.plot(event.xdata, event.ydata, 'rx', markersize=10)\n",
    "    ax.annotate(f'{len(ann_points[cam.name])}', xy=(event.xdata+10, event.ydata+7), textcoords='data')\n",
    "    ann_points[cam.name].append(([event.xdata, event.ydata]))\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    pass\n",
    "\n",
    "def update_cam(change):\n",
    "    ax.cla()\n",
    "    global cam\n",
    "    cam_name = change.new\n",
    "    cam = next(cam for cam in mvvids.cams if cam.name == cam_name)\n",
    "    ax.set_title(f\"Camera: {cam.name}\")\n",
    "    ax.imshow(base_frames[cam.name][0])\n",
    "    for i, point in enumerate(ann_points[cam.name]):\n",
    "        ax.plot(point[0], point[1], 'rx', markersize=10)\n",
    "        ax.annotate(f'{i}', xy=(point[0]+10, point[1]+7), textcoords='data')\n",
    "    fig.canvas.draw()\n",
    "    pass\n",
    "\n",
    "cam_dropdown.observe(update_cam, names='value')\n",
    "\n",
    "cam = mvvids.cams[0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.imshow(base_frames[cam.name][0])\n",
    "\n",
    "for i, point in enumerate(ann_points[cam.name]):\n",
    "    ax.plot(point[0], point[1], 'rx', markersize=10)\n",
    "    ax.annotate(f'{i}', xy=(point[0]+10, point[1]+7), textcoords='data')\n",
    "    \n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', lambda event: onclick(event, cam))\n",
    "\n",
    "display(cam_dropdown)\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cf504-c9da-440c-94d6-dd16f1422fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "\n",
    "for cam_name, points in ann_points.items():\n",
    "    print(cam_name,\":\")\n",
    "    print(\"\\t\",points)\n",
    "    if len(points) > 1:\n",
    "        print(\"Only select one point at a time, please re-execute previous cell before continuing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13289b00-f47e-41c0-8713-0ea65174fc1a",
   "metadata": {},
   "source": [
    "If the scene is aligned properly we expect point on the floor to have there third coordinate (z) to be zero.\n",
    "If it's not the case we'll need to realign the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6634a-a1df-4bf8-862f-a62055fef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_2d = []\n",
    "calibs = []\n",
    "\n",
    "for cam_name, points in ann_points.items():\n",
    "    if len(points) == 0:\n",
    "        continue\n",
    "\n",
    "    obs_2d.append(points[0])\n",
    "    calibs.append(mvvids.get_cam_by_name(cam_name).get_calib())\n",
    "\n",
    "\n",
    "triangulated_point = triangulate_point(obs_2d, calibs)\n",
    "print(triangulated_point)\n",
    "                  \n",
    "point_3ds.append(triangulated_point.squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab86cd-dbba-43e8-8497-4b95bdb83568",
   "metadata": {},
   "source": [
    "### You can repeat the last three cell to add more ground matching point. The more the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fdfb1-05a9-4aa4-a70a-643611608186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize groundplane\n",
    "plt.close('all')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "all_reproj_2d = []\n",
    "for cam in mvvids.cams:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img = base_frames[cam.name][0]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "\n",
    "    reproj_2d, _ = cam.convert_to_camera_frame(np.vstack(point_3ds))\n",
    "    all_reproj_2d.append(reproj_2d)\n",
    "    plt.scatter(reproj_2d[:,0],reproj_2d[:,1], c=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0288ef-e9de-4bff-9a53-38322d803814",
   "metadata": {},
   "source": [
    "### Project the point on the ground using the groundplane assumption. If the ground is correctly alligned the point should overlap or be very close to each other, if it's not the case proceed with realignement below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7428d-c43e-4168-a709-cc4d5343993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_point_g = []\n",
    "\n",
    "for i, cam in enumerate(mvvids.cams):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    img_ground = ground_imgs[i]\n",
    "\n",
    "    input_img_size = base_frames[cam.name][0].shape[:2]\n",
    "\n",
    "    H = cam.get_ground_plane_homography(input_img_size=input_img_size, output_img_size = output_img_size, \n",
    "                                        bounding_box = rect, padding_percent = padding_percent)\n",
    "\n",
    "    point_cam_g = project_points(all_reproj_2d[i], np.linalg.inv(H))\n",
    "    print(point_cam_g,point_cam_g.shape)\n",
    "    all_point_g.append(point_cam_g.squeeze())\n",
    "    \n",
    "    plt.imshow(img_ground)\n",
    "    plt.scatter(point_cam_g[:,0], point_cam_g[:,1], c=\"red\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#Overal images to see alignement\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, img in enumerate(ground_imgs):\n",
    "    plt.imshow(img, alpha=1-i/len(ground_imgs))\n",
    "\n",
    "\n",
    "all_point_g = np.vstack(all_point_g)\n",
    "\n",
    "\n",
    "plt.scatter(all_point_g[:,0], all_point_g[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230abab-9fdb-4d74-be1b-7b43978a090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_offsets = np.vstack(point_3ds)[:,2].mean()\n",
    "\n",
    "print(f\"z_offsets = {z_offsets} if the value is close to zero you can stop here the calibration is complete, otherwise proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26afb7-cb1c-4a62-b910-838451f89de3",
   "metadata": {},
   "source": [
    "## Scaling reconstruction to match real world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a6a87-9842-4582-9963-f7870ca81249",
   "metadata": {},
   "source": [
    "Select two points on the ground which the distance between the two (in cm) is roughly known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b24ffc-7e31-4e8e-85f4-68d4b21e85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "world_scale_point = {cam.name: [] for cam in mvvids.cams}\n",
    "\n",
    "# create dropdown widget with camera names as options\n",
    "cam_dropdown = widgets.Dropdown(\n",
    "    options=[cam.name for cam in mvvids.cams],\n",
    "    value=mvvids.cams[0].name,\n",
    "    description='Camera:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def onclick(event, cam):\n",
    "    ax.plot(event.xdata, event.ydata, 'rx', markersize=10)\n",
    "    ax.annotate(f'{len(world_scale_point[cam.name])}', xy=(event.xdata+10, event.ydata+7), textcoords='data')\n",
    "    world_scale_point[cam.name].append(([event.xdata, event.ydata]))\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    pass\n",
    "\n",
    "def update_cam(change):\n",
    "    ax.cla()\n",
    "    global cam\n",
    "    cam_name = change.new\n",
    "    cam = next(cam for cam in mvvids.cams if cam.name == cam_name)\n",
    "    ax.set_title(f\"Camera: {cam.name}\")\n",
    "    ax.imshow(base_frames[cam.name][0])\n",
    "    for i, point in enumerate(world_scale_point[cam.name]):\n",
    "        ax.plot(point[0], point[1], 'rx', markersize=10)\n",
    "        ax.annotate(f'{i}', xy=(point[0]+10, point[1]+7), textcoords='data')\n",
    "    fig.canvas.draw()\n",
    "    pass\n",
    "\n",
    "cam_dropdown.observe(update_cam, names='value')\n",
    "\n",
    "cam = mvvids.cams[0]\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.imshow(base_frames[cam.name][0])\n",
    "\n",
    "for i, point in enumerate(world_scale_point[cam.name]):\n",
    "    ax.plot(point[0], point[1], 'rx', markersize=10)\n",
    "    ax.annotate(f'{i}', xy=(point[0]+10, point[1]+7), textcoords='data')\n",
    "    \n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', lambda event: onclick(event, cam))\n",
    "\n",
    "display(cam_dropdown)\n",
    "# display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911517c0-c212-4a07-8fb8-dc660a7f764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "%matplotlib inline\n",
    "\n",
    "world_scale_point = {k:v for k,v in world_scale_point.items() if len(v) > 0}\n",
    "\n",
    "distance_between_point = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745275b2-2f86-44aa-b02e-740258269629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c43b7-2975-4473-bffc-36d8196201d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = mvvids.get_cam_by_name(list(world_scale_point.keys())[0])\n",
    "points = np.vstack(list(world_scale_point.values())[0])\n",
    "\n",
    "H = cam.get_ground_plane_homography(input_img_size=input_img_size, output_img_size = output_img_size, \n",
    "                                    bounding_box = rect, padding_percent = padding_percent)\n",
    "\n",
    "point_scale_ground = project_points(points, np.linalg.inv(H))\n",
    "\n",
    "dist_measured = np.linalg.norm(point_scale_ground[0]-point_scale_ground[1])\n",
    "print(f\"distance measure {dist_measured} should be {distance_between_point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b8c5b-c0b2-4500-a42d-30d5150687ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_rec = distance_between_point / dist_measured\n",
    "print(f\"Estimated reconstruction scaling factor {scale_rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00188de1-0b36-4c42-830e-4a0ef3889e63",
   "metadata": {},
   "source": [
    "# Updating calibration with z-offset and scaling information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2a408-1f6e-459d-bd21-383d648ba60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pairs_from_sequence, pairs_from_360\n",
    "\n",
    "tqdm.tqdm = tqdm.notebook.tqdm  # notebook-friendly progress bars\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "import copy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from hloc import (\n",
    "    extract_features,\n",
    "    match_features,\n",
    "    reconstruction,\n",
    "    visualization,\n",
    "    pairs_from_exhaustive\n",
    ")\n",
    "\n",
    "from hloc.localize_sfm import QueryLocalizer, pose_from_cluster\n",
    "from hloc.visualization import plot_images, read_image\n",
    "from hloc.utils import viz_3d\n",
    "import pycolmap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from configs.arguments import get_config_dict\n",
    "from utils.colmap_utils import add_camera_and_image, camera_calibs_from_colmap\n",
    "from utils.colmap_visualization import plot_reconstruction\n",
    "from utils.multiview_utils import Camera, Calibration\n",
    "from utils.metadata_utils import get_cam_names\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d1b5f-1264-45a7-9332-5599c25dc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(config.get('main', {}).get('data_root', DATAPATH))\n",
    "\n",
    "    \n",
    "RESTART = config[\"calibration\"][\"force_reconstruction\"]\n",
    "\n",
    "images = data_root / \"0-calibration/images\"\n",
    "outputs = data_root / \"0-calibration/outputs/\"\n",
    "\n",
    "sfm_pairs = outputs / \"pairs-sfm.txt\"\n",
    "loc_pairs = outputs / \"pairs-loc.txt\"\n",
    "sfm_dir = outputs / \"sfm\"\n",
    "features = outputs / \"features.h5\"\n",
    "matches = outputs / \"matches.h5\"\n",
    "model_dir = outputs / 'full_reconstruction/'\n",
    "\n",
    "rec_already_exists = (outputs / \"full_reconstruction\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44f2da-94ed-45f0-b6c3-e3059741e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pycolmap.Reconstruction(outputs / \"full_reconstruction\")\n",
    "references = [p.relative_to(images).as_posix() for p in images.rglob('*.jpg') if '360' in p.parent.name]\n",
    "query = [p.relative_to(images).as_posix() for p in images.rglob('*.jpg') if '360' not in p.parent.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591eb105-f8fd-4049-bf57-cdc0f693deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera = pycolmap.infer_camera_from_image(images / query)\n",
    "ref_ids = [model.find_image_with_name(r).image_id for r in references if model.find_image_with_name(r) is not None]\n",
    "conf = {\n",
    "    \"estimation\": {\"ransac\": {\"max_error\": 12}},\n",
    "    \"refinement\": {\"refine_focal_length\": False, \"refine_extra_params\": False},\n",
    "}\n",
    "\n",
    "localizer = QueryLocalizer(model, conf)\n",
    "rets = []\n",
    "logs = []\n",
    "for query_ in query:\n",
    "    camera = pycolmap.infer_camera_from_image(images / query_)\n",
    "    camera.params = [640, 640, 340, 0]\n",
    "    ret, pose_log = pose_from_cluster(localizer, query_, camera, ref_ids, features, matches)\n",
    "    ret['image'] = query_\n",
    "    # add results to reconstruction\n",
    "    try:\n",
    "        add_camera_and_image(model, ret['camera'], ret[\"cam_from_world\"], ret[\"image\"])\n",
    "    except ValueError as e:\n",
    "        log.error(e)\n",
    "\n",
    "    rets.append(ret)\n",
    "    logs.append(pose_log)\n",
    "\n",
    "    print(f'found {ret[\"num_inliers\"]}/{len(ret[\"inliers\"])} inlier correspondences.')\n",
    "\n",
    "\n",
    "temp_model = copy.deepcopy(model)\n",
    "\n",
    "# Transform the model\n",
    "temp_model.transform(pycolmap.Sim3d(1, pycolmap.Rotation3d([-0.7071068, 0, 0, 0.7071068]), [0, 0, 0]))\n",
    "\n",
    "# Filter out outlier and use bbox to set initial z=0\n",
    "bbox = temp_model.compute_bounding_box(0.01, 0.99)\n",
    "temp_model.transform(pycolmap.Sim3d(1, pycolmap.Rotation3d([0, 0, 0, 1]), [0, 0, -temp_model.compute_bounding_box(0.01, 0.99)[0][2]]))\n",
    "temp_model.transform(pycolmap.Sim3d(100, pycolmap.Rotation3d([0, 0, 0, 1]), [0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c08be-ace4-4445-99fc-bac80f22f9b8",
   "metadata": {},
   "source": [
    "## Updating and saving extrinsic calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bff00-160a-4d99-8c95-fe1efc2e4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'z_offsets' in locals():\n",
    "  z_offsets = 0\n",
    "\n",
    "if not 'scale_rec' in locals():\n",
    "  scale_rec = 1\n",
    "\n",
    "print(f\"Updating reconstruction with scaling of {scale_rec} and z offset of {z_offsets}\")\n",
    "temp_model.transform(pycolmap.Sim3d(scale_rec, pycolmap.Rotation3d([0, 0, 0, 1]), [0, 0, -z_offsets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf48b7-e271-4342-bfb9-799f9545bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = camera_calibs_from_colmap(images, temp_model, save=True)\n",
    "\n",
    "print(\"Extrinsic camera calibration completed. Restart the notebook to verify again groundplane alignement\")\n",
    "\n",
    "# Visualize the reconstruction\n",
    "plot_reconstruction(temp_model, save_path=outputs / \"360-reconstruction_w_static_updated.html\")\n",
    "\n",
    "print(f\"Scene visualization completed. Results saved in {outputs / '360-reconstruction_w_static_updated.html'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95ee2b-0581-4143-8325-f50e7a39ae76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
